# Model information for different providers

# Anthropic models
ANTHROPIC_MODELS = {
    "Claude 3.7 Sonnet (February 2025)": "claude-3-7-sonnet-20250219",
    "Claude 3.5 Sonnet (October 2024)": "claude-3-5-sonnet-20241022",
    "Claude 3.5 Sonnet (June 2024)": "claude-3-5-sonnet-20240620",
    "Claude 3.5 Haiku (October 2024)": "claude-3-5-haiku-20241022",
    "Claude 3 Opus (February 2024)": "claude-3-opus-20240229",
    "Claude 3 Sonnet (February 2024, Deprecated)": "claude-3-sonnet-20240229",
    "Claude 3 Haiku (March 2024)": "claude-3-haiku-20240307",
    "Claude 2.1 (Deprecated)": "claude-2.1",
    "Claude 2.0 (Deprecated)": "claude-2.0"

}

# Google AI Studio models
GOOGLE_MODELS = {
    "Gemini 2.5 Pro Preview 05/06": "gemini-2.5-pro-preview-05-06",
    "Gemini 2.5 Pro Preview 03/25": "gemini-2.5-pro-exp-03-25",
    "Gemini 2.5 Flash Preview 04/17": "gemini-2.5-flash-preview-04-17",
    "Gemini 2.0 Flash": "gemini-2.0-flash",
    "Gemini 2.0 Flash Lite": "gemini-2.0-flash-lite",
    "Gemini 2.0 Pro Experimental 02-05": "gemini-2.0-pro-exp-02-05",
    "Gemini 2.0 Flash Thinking Experimental 01-21": "gemini-2.0-flash-thinking-exp-01-21",
    "Gemini 2.0 Flash Experimental": "gemini-2.0-flash-exp",
    "Gemini 1.5 Flash": "gemini-1.5-flash",
    "Gemini 1.5 Flash 8b": "gemini-1.5-flash-8b",
    "Gemini 1.5 Pro": "gemini-1.5-pro",
    "Gemma 3 1b Instruct": "gemma-3-1b-it",
    "Gemma 3 4b Instruct": "gemma-3-4b-it",
    "Gemma 3 12b Instruct": "gemma-3-12b-it",
    "Gemma 3 27b Instruct": "gemma-3-27b-it"
}

# AI21 models
AI21_MODELS = {
    "Jamba 1.6 Large": "jamba-1.6-large",
    "Jamba 1.6 Mini": "jamba-1.6-mini",
    "Jamba 1.5 Large": "jamba-1.5-large",
    "Jamba 1.5 Mini": "jamba-1.5-mini"
}

# OpenAI models
OPENAI_MODELS = {
    "GPT-4.1 (April 2025)": "gpt-4.1-2025-04-14",
    "GPT-4.1 Mini (April 2025)": "gpt-4.1-mini-2025-04-14",
    "GPT-4.1 Nano (April 2025)": "gpt-4.1-nano-2025-04-14",
    "ChatGPT 4o (Latest)": "chatgpt-4o-latest",
    "GPT-4o (Latest)": "gpt-4o-latest",
    "GPT-4o (November 2024)": "gpt-4o-2024-11-20",
    "GPT-4o (August 2024)": "gpt-4o-2024-08-06",
    "GPT-4o Mini (July 2024)": "gpt-4o-mini-2024-07-18",
    "GPT-4o (May 2024)": "gpt-4o-2024-05-13",
    "GPT-4 Turbo (April 2024)": "gpt-4-turbo-2024-04-09",
    "GPT-4 Turbo Preview (January 2024)": "gpt-4-0125-preview",
    "GPT-4 Turbo Vision Preview (November 2023)": "gpt-4-1106-vision-preview",
    "GPT-4 (June 2023)": "gpt-4-0613",
    "GPT-4 (March 2023)": "gpt-4-0314",
    "GPT-3.5 Turbo (January 2024)": "gpt-3.5-0125",
    "GPT-3.5 Turbo (November 2023)": "gpt-3.5-1106",
    "GPT-3.5 Turbo Instruct": "gpt-3.5-turbo-instruct",
    "OpenAI o1 (December 2024)": "o1-2024-12-17",
    "OpenAI o1 Preview (September 2024)": "o1-preview-2024-09-12",
    "OpenAI o1 Mini (September 2024)": "o1-mini-2024-09-12",
    "OpenAI o3 (April 2025)": "o3-2025-04-16",
    "OpenAI o3 Mini (January 2025)": "o3-mini-2025-01-31",
    "OpenAI o4 Mini (April 2025)": "o4-mini-2025-04-16"

}

# Deepseek models
DEEPSEEK_MODELS = {
    "DeepSeek Chat": "deepseek-chat"
}

# Cohere models
COHERE_MODELS = {
    "Command A (March 2025)": "command-a-03-2025",
    "Command R+ (August 2024)": "commad-r-plus-08-2024",
    "Command R (August 2024)": "command-r-08-2024",
    "Command R+": "command-r-plus",
    "Command R": "command-r",
    "Command R 7b (December 2024)": "command-r7b-12-2024",
    "C4AI Aya Expanse 32B": "c4ai-aya-expanse-32b",
    "C4AI Aya 23 8b": "c4ai-aya-23b-8b",
    "C4AI Aya 23": "c4ai-aya-23"
}

# Mistral models
MISTRAL_MODELS = {
    "Mistral Large": "mistral-large-latest",
    "Mistral Small": "mistral-small-latest",
    "Open Mistral Nemo": "open-mistral-nemo",
    "Ministral 8B": "ministral-8b-latest",
    "Mistral Medium": "mistral-medium-latest",
    "Mistral Saba (Middle Eastern/South Asia)": "mistral-saba-latest"
}

# Featherless models
FEATHERLESS_MODELS = {
    "Qwen 2.5 72B": "Qwen/Qwen2.5-72B-Instruct",
    "Qwen 2.5 32B": "Qwen/Qwen2.5-32B-Instruct",
    "Qwen 2.5 14B": "Qwen/Qwen2.5-14B-Instruct",
    "Qwen 2.5 7B": "Qwen/Qwen2.5-7B-Instruct",
    "QWQ 32B": :"Qwen/QwQ-32B",
    "Qwerky 72B": "featherless-ai/Qwerky-72B-Preview",
    "DeepSeek R1": "deepseek-ai/DeepSeek-R1",
    "DeepSeek v3 (March 2025)": "deepseek-ai/DeepSeek-V3-0324",
    "Llama 3.3 70B": "meta-llama/Llama-3.3-70B-Instruct",
    "Qwen 2.5 Bakeneko 32B": "rinna/qwen2.5-bakeneko-32b-instruct-v2",
    "QWQ Bakeneko 32B": "rinna/qwq-bakeneko-32b",
    "Gemma 3 27b Instruct (Gated)": "google/gemma-3-27b-it",
    "Gemma 3 27b Pretrain (Gated)": "google/gemma-3-27b-pt",
    "Gemma 3 12b Instruct (Gated)": "google/gemma-3-12b-it",
    "Mistral Small 3.1 24B Instruct (Gated)": "mistralai/Mistral-Small-3.1-24B-Instruct-2503"    

}

# ArliAI models
ARLIAI_MODELS = {
    "Qwen 2.5 72B": "Qwen2.5-72B-Instruct",
    "Qwen 2.5 32B": "Qwen2.5-32B-Instruct",
    "Llama 3.3 70B": "Llama-3.3-70B-Instruct",
    "Mistral Nemo 12B": "Mistral-Nemo-12B-Instruct-2407",
    "Mistral Small 24B": "Mistral-Small-24B-Instruct-2501",
}

# Openrouter models - This would typically be fetched from their API
OPENROUTER_MODELS = {
    "Claude 3.7 Sonnet": "anthropic/claude-3.7-sonnet",
    "Claude 3.7 Sonnet (Thinking)": "anthropic/claude-3.7-sonnet:thinking",
    "Claude 3.5 Sonnet (Latest)": "anthropic/claude-3.5-sonnet",
    "Claude 3.5 Sonnet (June 2024)": "anthropic/claude-3.5-sonnet-20240620",
    "Claude 3 Opus": "anthropic/claude-3-opus",
    "Jamba 1.6 Large": "ai21/jamba-1.6-large",
    "Jamba 1.6 Mini": "ai21/jamba-1.6-mini",
    "Jamba 1.5 Large": "ai21/jamba-1.5-large",
    "Jamba 1.5 Mini": "ai21/jamba-1.5-mini",
    "Jamba Instruct": "ai21/jamba-instruct",
    "Command A": "cohere/command-a",
    "Command R+ (August 2024)": "cohere/command-r-plus-08-2024",
    "Command R (August 2024)": "cohere/command-r-08-2024",
    "Command R 7B (December 2024)": "cohere/command-r7b-12-2024",
    "DeepSeek Chat (Free)": "deepseek/deepseek-chat:free",
    "DeepSeek R1 (Free)": "deepseek/deepseek-r1:free",
    "DeepSeek Chat v3 (Free)": "deepseek/deepseek-chat-v3-0324:free",
    "Gemma 3 1B (Free)": "google/gemma-3-1b-it:free",
    "Gemma 3 4B (Free)": "google/gemma-3-4b-it:free",
    "Gemma 2 9B (Free)": "google/gemma-2-9b-it:free",
    "Gemma 3 12B (Free)": "google/gemma-3-12b-it:free",
    "Gemma 3 27B (Free)": "google/gemma-3-27b-it:free",
    "Gemini 2.0 Flash": "google/gemini-2.0-flash-001",
    "Gemini 2.0 Flash Lite": "google/gemini-2.0-flash-lite-001",
    "Gemini 2.0 Flash Lite Preview (Free)": "google/gemini-2.0-flash-lite-preview-02-05:free",
    "Gemini 2.0 Pro Exp (Free)": "google/gemini-2.0-pro-exp-02-05:free",
    "Gemini 2.0 Flash Exp (Free)": "google/gemini-2.0-flash-exp:free",
    "Gemini Exp 1206 (Free)": "google/gemini-exp-1206:free",
    "Gemini Flash 1.5": "google/gemini-flash-1.5",
    "Gemini Pro 1.5": "google/gemini-pro-1.5",
    "Mistral Small 3.1 24B (Free)": "mistralai/mistral-small-3.1-24b-instruct:free",
    "Mistral Small 24B (Free)": "mistralai/mistral-small-24b-instruct-2501:free",
    "Mistral Large (November 2024)": "mistralai/mistral-large-2411",
    "Mistral Nemo (Free)": "mistralai/mistral-nemo:free",
    "Qwen 2.5 72B (Free)": "qwen/qwen-2.5-72b-instruct:free",
    "GPT-4o": "openai/gpt-4o"    
}

# OAI Compatible models - This would typically be fetched from the API
OAICOMPAT_MODELS = {
    "Mistral Nemo Japanese": "koboldcpp/mistral-nemo-japanese-instruct-2408-q6_k",
    "Mistral 7B": "mistral-7b"
}

# All models in one dictionary
ALL_MODELS = {
    "Anthropic": ANTHROPIC_MODELS,
    "Google AI Studio": GOOGLE_MODELS,
    "AI21": AI21_MODELS,
    "OpenAI": OPENAI_MODELS,
    "Deepseek": DEEPSEEK_MODELS,
    "Cohere": COHERE_MODELS,
    "Mistral": MISTRAL_MODELS,
    "Featherless": FEATHERLESS_MODELS,
    "ArliAI": ARLIAI_MODELS,
    "Openrouter": OPENROUTER_MODELS,
    "OpenAI Compatible": OAICOMPAT_MODELS
}


def get_model_display_name(provider, model_id):
    """Get a user-friendly display name for a model."""
    provider_models = ALL_MODELS.get(provider, {})
    # Need to search for the model_id in the values and return the key
    for display_name, id in provider_models.items():
        if id == model_id:
            return display_name
    return model_id  # Fallback to model_id if not found


def get_models_for_provider(provider):
    """Get all models for a specific provider."""
    return ALL_MODELS.get(provider, {})


def is_valid_model(provider, model_id):
    """Check if a model ID is valid for a provider."""
    provider_models = ALL_MODELS.get(provider, {})
    # Check if model_id is in the values
    return model_id in provider_models.values()